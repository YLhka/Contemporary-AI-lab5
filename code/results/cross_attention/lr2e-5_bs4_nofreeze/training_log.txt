Training started at: 2026-01-28 11:45:33
Command: train_cross_attention.py --train-file cleaned/train_clean.txt --val-file cleaned/val_clean.txt --data-dir data --fusion cross --epochs 10 --batch-size 4 --lr 2e-5 --output-dir results/cross_attention/lr2e-5_bs4_nofreeze --output best_cross_attention_lr2e-5_bs4_nofreeze.pt

Device: cuda
PyTorch version: 2.6.0+cu124
CUDA version: 12.4
GPU: NVIDIA GeForce RTX 4060 Laptop GPU
Class weights: [0.5584642291069031, 1.1169284582138062, 3.184079647064209]
===== Epoch 1 =====
Train loss: 0.9980 | Val loss: 0.9681
Val macro-F1: 0.4588 | Val weighted-F1: 0.5812 | Val acc: 0.5863

Classification Report:
              precision    recall  f1-score   support

    positive     0.8112    0.5753    0.6732       478
    negative     0.4199    0.7815    0.5463       238
     neutral     0.4444    0.0952    0.1569        84

    accuracy                         0.5863       800
   macro avg     0.5585    0.4840    0.4588       800
weighted avg     0.6563    0.5863    0.5812       800


Confusion Matrix:
[[275 196   7]
 [ 49 186   3]
 [ 15  61   8]]

Saved best model: best_cross_attention_lr2e-5_bs4_nofreeze.pt
===== Epoch 2 =====
Train loss: 0.6531 | Val loss: 0.8628
Val macro-F1: 0.5550 | Val weighted-F1: 0.6667 | Val acc: 0.6500

Classification Report:
              precision    recall  f1-score   support

    positive     0.8119    0.7134    0.7595       478
    negative     0.6109    0.6134    0.6122       238
     neutral     0.2340    0.3929    0.2933        84

    accuracy                         0.6500       800
   macro avg     0.5523    0.5732    0.5550       800
weighted avg     0.6914    0.6500    0.6667       800


Confusion Matrix:
[[341  68  69]
 [ 53 146  39]
 [ 26  25  33]]

Saved best model: best_cross_attention_lr2e-5_bs4_nofreeze.pt
===== Epoch 3 =====
Train loss: 0.2026 | Val loss: 1.6268
Val macro-F1: 0.5368 | Val weighted-F1: 0.6622 | Val acc: 0.6900

Classification Report:
              precision    recall  f1-score   support

    positive     0.7110    0.9059    0.7967       478
    negative     0.6944    0.4202    0.5236       238
     neutral     0.4043    0.2262    0.2901        84

    accuracy                         0.6900       800
   macro avg     0.6032    0.5174    0.5368       800
weighted avg     0.6739    0.6900    0.6622       800


Confusion Matrix:
[[433  32  13]
 [123 100  15]
 [ 53  12  19]]

Early stopping counter: 1/3
===== Epoch 4 =====
Train loss: 0.0643 | Val loss: 1.5818
Val macro-F1: 0.5671 | Val weighted-F1: 0.6768 | Val acc: 0.6763

Classification Report:
              precision    recall  f1-score   support

    positive     0.7673    0.7866    0.7769       478
    negative     0.6326    0.5714    0.6004       238
     neutral     0.3053    0.3452    0.3240        84

    accuracy                         0.6763       800
   macro avg     0.5684    0.5678    0.5671       800
weighted avg     0.6787    0.6763    0.6768       800


Confusion Matrix:
[[376  59  43]
 [ 79 136  23]
 [ 35  20  29]]

Saved best model: best_cross_attention_lr2e-5_bs4_nofreeze.pt
===== Epoch 5 =====
Train loss: 0.0535 | Val loss: 1.9348
Val macro-F1: 0.5414 | Val weighted-F1: 0.6841 | Val acc: 0.7100

Classification Report:
              precision    recall  f1-score   support

    positive     0.7330    0.9017    0.8086       478
    negative     0.7045    0.5210    0.5990       238
     neutral     0.3611    0.1548    0.2167        84

    accuracy                         0.7100       800
   macro avg     0.5995    0.5258    0.5414       800
weighted avg     0.6855    0.7100    0.6841       800


Confusion Matrix:
[[431  33  14]
 [105 124   9]
 [ 52  19  13]]

Early stopping counter: 1/3
===== Epoch 6 =====
Train loss: 0.0365 | Val loss: 1.8887
Val macro-F1: 0.5375 | Val weighted-F1: 0.6782 | Val acc: 0.6963

Classification Report:
              precision    recall  f1-score   support

    positive     0.7591    0.8305    0.7932       478
    negative     0.6066    0.6218    0.6141       238
     neutral     0.3636    0.1429    0.2051        84

    accuracy                         0.6963       800
   macro avg     0.5764    0.5317    0.5375       800
weighted avg     0.6722    0.6963    0.6782       800


Confusion Matrix:
[[397  68  13]
 [ 82 148   8]
 [ 44  28  12]]

Early stopping counter: 2/3
===== Epoch 7 =====
Train loss: 0.0397 | Val loss: 1.9150
Val macro-F1: 0.5558 | Val weighted-F1: 0.6875 | Val acc: 0.7063

Classification Report:
              precision    recall  f1-score   support

    positive     0.7434    0.8849    0.8080       478
    negative     0.6927    0.5210    0.5947       238
     neutral     0.3462    0.2143    0.2647        84

    accuracy                         0.7063       800
   macro avg     0.5941    0.5401    0.5558       800
weighted avg     0.6866    0.7063    0.6875       800


Confusion Matrix:
[[423  37  18]
 [ 98 124  16]
 [ 48  18  18]]

Early stopping counter: 3/3
Early stopping triggered!
Saved metrics to: results/cross_attention/lr2e-5_bs4_nofreeze\metrics.csv

===== Final Evaluation =====
Best val macro-F1: 0.5671
Final val macro-F1: 0.5671 | Final val weighted-F1: 0.6768 | Final val acc: 0.6763

Final Classification Report:
              precision    recall  f1-score   support

    positive     0.7673    0.7866    0.7769       478
    negative     0.6326    0.5714    0.6004       238
     neutral     0.3053    0.3452    0.3240        84

    accuracy                         0.6763       800
   macro avg     0.5684    0.5678    0.5671       800
weighted avg     0.6787    0.6763    0.6768       800


Final Confusion Matrix:
[[376  59  43]
 [ 79 136  23]
 [ 35  20  29]]
Saved final report to: results/cross_attention/lr2e-5_bs4_nofreeze\final_report.txt

All results saved to: results/cross_attention/lr2e-5_bs4_nofreeze
