Training started at: 2026-01-28 09:10:29
Command: train_cross_attention.py --train-file cleaned/train_clean.txt --val-file cleaned/val_clean.txt --data-dir data --fusion cross --epochs 10 --batch-size 32 --lr 1e-4 --output-dir results/cross_attention/lr1e-4_bs32_nofreeze --output best_cross_attention_lr1e-4_bs32_nofreeze.pt

Device: cuda
PyTorch version: 2.6.0+cu124
CUDA version: 12.4
GPU: NVIDIA GeForce RTX 4060 Laptop GPU
Class weights: [0.5584642291069031, 1.1169284582138062, 3.184079647064209]
===== Epoch 1 =====
Train loss: 0.9980 | Val loss: 1.0989
Val macro-F1: 0.4954 | Val weighted-F1: 0.6227 | Val acc: 0.6375

Classification Report:
              precision    recall  f1-score   support

    positive     0.7170    0.7845    0.7493       478
    negative     0.5063    0.5084    0.5073       238
     neutral     0.3684    0.1667    0.2295        84

    accuracy                         0.6375       800
   macro avg     0.5306    0.4865    0.4954       800
weighted avg     0.6177    0.6375    0.6227       800


Confusion Matrix:
[[375  87  16]
 [109 121   8]
 [ 39  31  14]]

Saved best model: best_cross_attention_lr1e-4_bs32_nofreeze.pt
===== Epoch 2 =====
Train loss: 0.6423 | Val loss: 1.0004
Val macro-F1: 0.5310 | Val weighted-F1: 0.6371 | Val acc: 0.6350

Classification Report:
              precision    recall  f1-score   support

    positive     0.7995    0.6674    0.7275       478
    negative     0.4899    0.7101    0.5798       238
     neutral     0.3571    0.2381    0.2857        84

    accuracy                         0.6350       800
   macro avg     0.5488    0.5385    0.5310       800
weighted avg     0.6609    0.6350    0.6371       800


Confusion Matrix:
[[319 135  24]
 [ 57 169  12]
 [ 23  41  20]]

Saved best model: best_cross_attention_lr1e-4_bs32_nofreeze.pt
===== Epoch 3 =====
Train loss: 0.2465 | Val loss: 1.5089
Val macro-F1: 0.5257 | Val weighted-F1: 0.6401 | Val acc: 0.6425

Classification Report:
              precision    recall  f1-score   support

    positive     0.7495    0.7448    0.7471       478
    negative     0.5331    0.5756    0.5535       238
     neutral     0.3088    0.2500    0.2763        84

    accuracy                         0.6425       800
   macro avg     0.5305    0.5235    0.5257       800
weighted avg     0.6388    0.6425    0.6401       800


Confusion Matrix:
[[356  92  30]
 [ 84 137  17]
 [ 35  28  21]]

Early stopping counter: 1/3
===== Epoch 4 =====
Train loss: 0.1286 | Val loss: 1.7977
Val macro-F1: 0.5439 | Val weighted-F1: 0.6558 | Val acc: 0.6600

Classification Report:
              precision    recall  f1-score   support

    positive     0.7292    0.7887    0.7578       478
    negative     0.6364    0.5294    0.5780       238
     neutral     0.2941    0.2976    0.2959        84

    accuracy                         0.6600       800
   macro avg     0.5532    0.5386    0.5439       800
weighted avg     0.6559    0.6600    0.6558       800


Confusion Matrix:
[[377  58  43]
 [ 95 126  17]
 [ 45  14  25]]

Saved best model: best_cross_attention_lr1e-4_bs32_nofreeze.pt
===== Epoch 5 =====
Train loss: 0.0463 | Val loss: 2.2071
Val macro-F1: 0.5328 | Val weighted-F1: 0.6527 | Val acc: 0.6600

Classification Report:
              precision    recall  f1-score   support

    positive     0.7425    0.7782    0.7600       478
    negative     0.5732    0.5756    0.5744       238
     neutral     0.3167    0.2262    0.2639        84

    accuracy                         0.6600       800
   macro avg     0.5441    0.5267    0.5328       800
weighted avg     0.6474    0.6600    0.6527       800


Confusion Matrix:
[[372  78  28]
 [ 88 137  13]
 [ 41  24  19]]

Early stopping counter: 1/3
===== Epoch 6 =====
Train loss: 0.0406 | Val loss: 2.0447
Val macro-F1: 0.5159 | Val weighted-F1: 0.6372 | Val acc: 0.6388

Classification Report:
              precision    recall  f1-score   support

    positive     0.7549    0.7280    0.7412       478
    negative     0.5351    0.6092    0.5697       238
     neutral     0.2647    0.2143    0.2368        84

    accuracy                         0.6388       800
   macro avg     0.5182    0.5172    0.5159       800
weighted avg     0.6380    0.6388    0.6372       800


Confusion Matrix:
[[348  97  33]
 [ 76 145  17]
 [ 37  29  18]]

Early stopping counter: 2/3
===== Epoch 7 =====
Train loss: 0.0274 | Val loss: 2.2133
Val macro-F1: 0.5303 | Val weighted-F1: 0.6597 | Val acc: 0.6713

Classification Report:
              precision    recall  f1-score   support

    positive     0.7361    0.8054    0.7692       478
    negative     0.6126    0.5714    0.5913       238
     neutral     0.2909    0.1905    0.2302        84

    accuracy                         0.6713       800
   macro avg     0.5466    0.5224    0.5303       800
weighted avg     0.6526    0.6713    0.6597       800


Confusion Matrix:
[[385  66  27]
 [ 90 136  12]
 [ 48  20  16]]

Early stopping counter: 3/3
Early stopping triggered!
Saved metrics to: results/cross_attention/lr1e-4_bs32_nofreeze\metrics.csv

===== Final Evaluation =====
Best val macro-F1: 0.5439
Final val macro-F1: 0.5439 | Final val weighted-F1: 0.6558 | Final val acc: 0.6600

Final Classification Report:
              precision    recall  f1-score   support

    positive     0.7292    0.7887    0.7578       478
    negative     0.6364    0.5294    0.5780       238
     neutral     0.2941    0.2976    0.2959        84

    accuracy                         0.6600       800
   macro avg     0.5532    0.5386    0.5439       800
weighted avg     0.6559    0.6600    0.6558       800


Final Confusion Matrix:
[[377  58  43]
 [ 95 126  17]
 [ 45  14  25]]
Saved final report to: results/cross_attention/lr1e-4_bs32_nofreeze\final_report.txt

All results saved to: results/cross_attention/lr1e-4_bs32_nofreeze
