Training started at: 2026-01-28 11:03:52
Command: train_cross_attention.py --train-file cleaned/train_clean.txt --val-file cleaned/val_clean.txt --data-dir data --fusion cross --epochs 10 --batch-size 4 --lr 1e-5 --output-dir results/cross_attention/lr1e-5_bs4_nofreeze --output best_cross_attention_lr1e-5_bs4_nofreeze.pt

Device: cuda
PyTorch version: 2.6.0+cu124
CUDA version: 12.4
GPU: NVIDIA GeForce RTX 4060 Laptop GPU
Class weights: [0.5584642291069031, 1.1169284582138062, 3.184079647064209]
===== Epoch 1 =====
Train loss: 1.0095 | Val loss: 0.9643
Val macro-F1: 0.4487 | Val weighted-F1: 0.5624 | Val acc: 0.5650

Classification Report:
              precision    recall  f1-score   support

    positive     0.8000    0.5439    0.6476       478
    negative     0.4049    0.7689    0.5304       238
     neutral     0.3913    0.1071    0.1682        84

    accuracy                         0.5650       800
   macro avg     0.5321    0.4733    0.4487       800
weighted avg     0.6395    0.5650    0.5624       800


Confusion Matrix:
[[260 209   9]
 [ 50 183   5]
 [ 15  60   9]]

Saved best model: best_cross_attention_lr1e-5_bs4_nofreeze.pt
===== Epoch 2 =====
Train loss: 0.6629 | Val loss: 0.9109
Val macro-F1: 0.5274 | Val weighted-F1: 0.6275 | Val acc: 0.6125

Classification Report:
              precision    recall  f1-score   support

    positive     0.7843    0.6464    0.7087       478
    negative     0.5435    0.6303    0.5837       238
     neutral     0.2385    0.3690    0.2897        84

    accuracy                         0.6125       800
   macro avg     0.5221    0.5486    0.5274       800
weighted avg     0.6553    0.6125    0.6275       800


Confusion Matrix:
[[309 100  69]
 [ 58 150  30]
 [ 27  26  31]]

Saved best model: best_cross_attention_lr1e-5_bs4_nofreeze.pt
===== Epoch 3 =====
Train loss: 0.2195 | Val loss: 1.4614
Val macro-F1: 0.5158 | Val weighted-F1: 0.6529 | Val acc: 0.6775

Classification Report:
              precision    recall  f1-score   support

    positive     0.7088    0.8808    0.7854       478
    negative     0.6795    0.4454    0.5381       238
     neutral     0.3000    0.1786    0.2239        84

    accuracy                         0.6775       800
   macro avg     0.5627    0.5016    0.5158       800
weighted avg     0.6571    0.6775    0.6529       800


Confusion Matrix:
[[421  35  22]
 [119 106  13]
 [ 54  15  15]]

Early stopping counter: 1/3
===== Epoch 4 =====
Train loss: 0.0627 | Val loss: 1.5201
Val macro-F1: 0.5550 | Val weighted-F1: 0.6658 | Val acc: 0.6725

Classification Report:
              precision    recall  f1-score   support

    positive     0.7375    0.8054    0.7700       478
    negative     0.6305    0.5378    0.5805       238
     neutral     0.3333    0.2976    0.3145        84

    accuracy                         0.6725       800
   macro avg     0.5671    0.5470    0.5550       800
weighted avg     0.6633    0.6725    0.6658       800


Confusion Matrix:
[[385  57  36]
 [ 96 128  14]
 [ 41  18  25]]

Saved best model: best_cross_attention_lr1e-5_bs4_nofreeze.pt
===== Epoch 5 =====
Train loss: 0.0405 | Val loss: 1.7003
Val macro-F1: 0.5406 | Val weighted-F1: 0.6696 | Val acc: 0.6863

Classification Report:
              precision    recall  f1-score   support

    positive     0.7358    0.8389    0.7840       478
    negative     0.6256    0.5546    0.5880       238
     neutral     0.3636    0.1905    0.2500        84

    accuracy                         0.6863       800
   macro avg     0.5750    0.5280    0.5406       800
weighted avg     0.6639    0.6863    0.6696       800


Confusion Matrix:
[[401  56  21]
 [ 99 132   7]
 [ 45  23  16]]

Early stopping counter: 1/3
===== Epoch 6 =====
Train loss: 0.0334 | Val loss: 1.7213
Val macro-F1: 0.5239 | Val weighted-F1: 0.6484 | Val acc: 0.6550

Classification Report:
              precision    recall  f1-score   support

    positive     0.7542    0.7510    0.7526       478
    negative     0.5498    0.6261    0.5855       238
     neutral     0.3019    0.1905    0.2336        84

    accuracy                         0.6550       800
   macro avg     0.5353    0.5225    0.5239       800
weighted avg     0.6459    0.6550    0.6484       800


Confusion Matrix:
[[359  91  28]
 [ 80 149   9]
 [ 37  31  16]]

Early stopping counter: 2/3
===== Epoch 7 =====
Train loss: 0.0352 | Val loss: 1.7887
Val macro-F1: 0.5365 | Val weighted-F1: 0.6679 | Val acc: 0.6837

Classification Report:
              precision    recall  f1-score   support

    positive     0.7402    0.8285    0.7818       478
    negative     0.6126    0.5714    0.5913       238
     neutral     0.3488    0.1786    0.2362        84

    accuracy                         0.6837       800
   macro avg     0.5672    0.5262    0.5365       800
weighted avg     0.6611    0.6837    0.6679       800


Confusion Matrix:
[[396  61  21]
 [ 95 136   7]
 [ 44  25  15]]

Early stopping counter: 3/3
Early stopping triggered!
Saved metrics to: results/cross_attention/lr1e-5_bs4_nofreeze\metrics.csv

===== Final Evaluation =====
Best val macro-F1: 0.5550
Final val macro-F1: 0.5550 | Final val weighted-F1: 0.6658 | Final val acc: 0.6725

Final Classification Report:
              precision    recall  f1-score   support

    positive     0.7375    0.8054    0.7700       478
    negative     0.6305    0.5378    0.5805       238
     neutral     0.3333    0.2976    0.3145        84

    accuracy                         0.6725       800
   macro avg     0.5671    0.5470    0.5550       800
weighted avg     0.6633    0.6725    0.6658       800


Final Confusion Matrix:
[[385  57  36]
 [ 96 128  14]
 [ 41  18  25]]
Saved final report to: results/cross_attention/lr1e-5_bs4_nofreeze\final_report.txt

All results saved to: results/cross_attention/lr1e-5_bs4_nofreeze
