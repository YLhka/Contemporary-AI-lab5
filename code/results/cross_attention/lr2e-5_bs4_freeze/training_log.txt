Training started at: 2026-01-28 11:29:29
Command: train_cross_attention.py --train-file cleaned/train_clean.txt --val-file cleaned/val_clean.txt --data-dir data --fusion cross --epochs 10 --batch-size 4 --lr 2e-5 --freeze-text --freeze-image --output-dir results/cross_attention/lr2e-5_bs4_freeze --output best_cross_attention_lr2e-5_bs4_freeze.pt

Device: cuda
PyTorch version: 2.6.0+cu124
CUDA version: 12.4
GPU: NVIDIA GeForce RTX 4060 Laptop GPU
Class weights: [0.5584642291069031, 1.1169284582138062, 3.184079647064209]
===== Epoch 1 =====
Train loss: 1.0178 | Val loss: 0.9966
Val macro-F1: 0.4107 | Val weighted-F1: 0.5361 | Val acc: 0.5463

Classification Report:
              precision    recall  f1-score   support

    positive     0.8013    0.5063    0.6205       478
    negative     0.3906    0.8025    0.5254       238
     neutral     0.4444    0.0476    0.0860        84

    accuracy                         0.5463       800
   macro avg     0.5455    0.4521    0.4107       800
weighted avg     0.6417    0.5463    0.5361       800


Confusion Matrix:
[[242 234   2]
 [ 44 191   3]
 [ 16  64   4]]

Saved best model: best_cross_attention_lr2e-5_bs4_freeze.pt
===== Epoch 2 =====
Train loss: 0.8521 | Val loss: 0.9296
Val macro-F1: 0.5161 | Val weighted-F1: 0.5932 | Val acc: 0.5787

Classification Report:
              precision    recall  f1-score   support

    positive     0.8217    0.5397    0.6515       478
    negative     0.4724    0.7185    0.5700       238
     neutral     0.2742    0.4048    0.3269        84

    accuracy                         0.5787       800
   macro avg     0.5227    0.5543    0.5161       800
weighted avg     0.6603    0.5787    0.5932       800


Confusion Matrix:
[[258 156  64]
 [ 41 171  26]
 [ 15  35  34]]

Saved best model: best_cross_attention_lr2e-5_bs4_freeze.pt
===== Epoch 3 =====
Train loss: 0.7601 | Val loss: 0.9708
Val macro-F1: 0.5254 | Val weighted-F1: 0.6323 | Val acc: 0.6338

Classification Report:
              precision    recall  f1-score   support

    positive     0.7237    0.7615    0.7421       478
    negative     0.5779    0.4832    0.5263       238
     neutral     0.2857    0.3333    0.3077        84

    accuracy                         0.6338       800
   macro avg     0.5291    0.5260    0.5254       800
weighted avg     0.6343    0.6338    0.6323       800


Confusion Matrix:
[[364  65  49]
 [102 115  21]
 [ 37  19  28]]

Saved best model: best_cross_attention_lr2e-5_bs4_freeze.pt
===== Epoch 4 =====
Train loss: 0.6831 | Val loss: 1.0109
Val macro-F1: 0.5142 | Val weighted-F1: 0.6346 | Val acc: 0.6400

Classification Report:
              precision    recall  f1-score   support

    positive     0.7212    0.7845    0.7515       478
    negative     0.5928    0.4832    0.5324       238
     neutral     0.2558    0.2619    0.2588        84

    accuracy                         0.6400       800
   macro avg     0.5233    0.5099    0.5142       800
weighted avg     0.6341    0.6400    0.6346       800


Confusion Matrix:
[[375  60  43]
 [102 115  21]
 [ 43  19  22]]

Early stopping counter: 1/3
===== Epoch 5 =====
Train loss: 0.6234 | Val loss: 1.0559
Val macro-F1: 0.5198 | Val weighted-F1: 0.6364 | Val acc: 0.6450

Classification Report:
              precision    recall  f1-score   support

    positive     0.7231    0.7866    0.7535       478
    negative     0.5587    0.5000    0.5277       238
     neutral     0.3134    0.2500    0.2781        84

    accuracy                         0.6450       800
   macro avg     0.5317    0.5122    0.5198       800
weighted avg     0.6312    0.6450    0.6364       800


Confusion Matrix:
[[376  72  30]
 [103 119  16]
 [ 41  22  21]]

Early stopping counter: 2/3
===== Epoch 6 =====
Train loss: 0.5745 | Val loss: 1.0876
Val macro-F1: 0.5218 | Val weighted-F1: 0.6325 | Val acc: 0.6312

Classification Report:
              precision    recall  f1-score   support

    positive     0.7342    0.7510    0.7425       478
    negative     0.5694    0.5000    0.5324       238
     neutral     0.2647    0.3214    0.2903        84

    accuracy                         0.6312       800
   macro avg     0.5227    0.5242    0.5218       800
weighted avg     0.6358    0.6312    0.6325       800


Confusion Matrix:
[[359  68  51]
 [ 95 119  24]
 [ 35  22  27]]

Early stopping counter: 3/3
Early stopping triggered!
Saved metrics to: results/cross_attention/lr2e-5_bs4_freeze\metrics.csv

===== Final Evaluation =====
Best val macro-F1: 0.5254
Final val macro-F1: 0.5254 | Final val weighted-F1: 0.6323 | Final val acc: 0.6338

Final Classification Report:
              precision    recall  f1-score   support

    positive     0.7237    0.7615    0.7421       478
    negative     0.5779    0.4832    0.5263       238
     neutral     0.2857    0.3333    0.3077        84

    accuracy                         0.6338       800
   macro avg     0.5291    0.5260    0.5254       800
weighted avg     0.6343    0.6338    0.6323       800


Final Confusion Matrix:
[[364  65  49]
 [102 115  21]
 [ 37  19  28]]
Saved final report to: results/cross_attention/lr2e-5_bs4_freeze\final_report.txt

All results saved to: results/cross_attention/lr2e-5_bs4_freeze
